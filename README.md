# ğŸ• iFood Restaurant Scraper

Um sistema completo de **web scraping** para coleta de dados de restaurantes do iFood, desenvolvido com **Selenium**, **Beautiful Soup** e **Pandas**. O projeto extrai informaÃ§Ãµes detalhadas incluindo dados bÃ¡sicos dos restaurantes, localizaÃ§Ã£o, mÃ©todos de pagamento e informaÃ§Ãµes de entrega.

## ğŸš€ Funcionalidades

### ğŸ“Š Dados BÃ¡sicos dos Restaurantes
- **Nome do restaurante**
- **Nota de avaliaÃ§Ã£o** 
- **Tipo de culinÃ¡ria**
- **DistÃ¢ncia do usuÃ¡rio**
- **Tempo de entrega** (mÃ­nimo e mÃ¡ximo)
- **PreÃ§o do frete**
- **URL do restaurante**

### ğŸ“ InformaÃ§Ãµes de LocalizaÃ§Ã£o
- **EndereÃ§o completo**
- **Bairro**
- **Cidade e UF**
- **CEP**
- **Coordenadas do usuÃ¡rio** (latitude/longitude)
- **Geohash da localizaÃ§Ã£o**

### ğŸ’³ MÃ©todos de Pagamento
- **Pagamento pelo site**: DÃ©bito, CrÃ©dito, PIX, Vale-refeiÃ§Ã£o
- **Pagamento na entrega**: DÃ©bito, CrÃ©dito, PIX, Vale-refeiÃ§Ã£o, Dinheiro
- **Pedido mÃ­nimo** do restaurante

## ğŸ› ï¸ Tecnologias Utilizadas

- **[Selenium](https://selenium-python.readthedocs.io/)** - AutomaÃ§Ã£o do navegador
- **[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)** - Parsing de HTML
- **[Pandas](https://pandas.pydata.org/)** - ManipulaÃ§Ã£o de dados
- **[WebDriver Manager](https://github.com/SergeyPirogov/webdriver_manager)** - Gerenciamento automÃ¡tico do ChromeDriver

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/ifood-scraper.git
cd ifood-scraper
```

### 2. Instale as dependÃªncias
```bash
pip install pandas selenium beautifulsoup4 webdriver-manager pathlib
```

### 3. Verifique se o Chrome estÃ¡ instalado
O projeto utiliza o Google Chrome como navegador padrÃ£o.

## ğŸ¯ Como Usar

### Scraping BÃ¡sico de Restaurantes

```bash
# ExecuÃ§Ã£o padrÃ£o (10 scrolls)
python main.py

# Personalizar nÃºmero de scrolls
python main.py --scrolls 20

# Personalizar timeout
python main.py --timeout 15
```

### ExtraÃ§Ã£o de Detalhes Completos

```bash
# Extrair detalhes dos restaurantes (endereÃ§os + pagamentos)
python main_details.py

# Com timeout personalizado
python main_details.py --timeout 20

# Especificar diretÃ³rio do CSV
python main_details.py --directory "meus_dados"
```

### Teste de Funcionalidades

```bash
# Testar extraÃ§Ã£o de mÃ©todos de pagamento (5 restaurantes)
python test_payment_extraction.py
```

## ğŸ“ Estrutura do Projeto

```
ifood-scraper/
â”œâ”€â”€ ğŸ“„ main.py                          # Script principal simplificado
â”œâ”€â”€ ğŸ“„ main_details.py                  # ExtraÃ§Ã£o de detalhes completos
â”œâ”€â”€ ğŸ“„ test_payment_extraction.py       # Teste de mÃ©todos de pagamento
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“„ ifood_scraper.py            # Classe principal do scraper
â”‚   â”œâ”€â”€ ğŸ“„ restaurant_details_scraper.py # ExtraÃ§Ã£o de detalhes
â”‚   â””â”€â”€ ğŸ“ old/                        # VersÃµes anteriores
â”œâ”€â”€ ğŸ“ reports/                        # Arquivos CSV gerados
â”‚   â”œâ”€â”€ ğŸ“„ bd_scrap_ifood_*.csv        # Dados bÃ¡sicos dos restaurantes
â”‚   â”œâ”€â”€ ğŸ“„ details_bd_scrap_ifood_*.csv # Detalhes completos
â”‚   â””â”€â”€ ğŸ“„ teste_pagamentos_*.csv      # Testes de pagamento
â””â”€â”€ ğŸ“„ README.md
```

## ğŸ“Š Formatos de SaÃ­da

### Dados BÃ¡sicos (`bd_scrap_ifood_*.csv`)
```csv
Data,User_Latitude,User_Longitude,Geohash,URL,Restaurante,Nota,Tipo de comida,Distancia,Tempo Min,Tempo Max,Preco do Frete
2025-06-15 12:52:39,-18.9395041,-48.3059029,6utskb0v3k6t,https://...,McDonald's,4.6,Lanches,2.9,20,30,9.99
```

### Detalhes Completos (`details_bd_scrap_ifood_*.csv`)
```csv
URL,Restaurante,Pedido_Minimo,Endereco,Bairro,Cidade,UF,CEP,Pag_Site_Debito,Pag_Site_Credito,Pag_Site_PIX,Pag_Site_Vale_Refeicao,Pag_Entrega_Debito,Pag_Entrega_Credito,Pag_Entrega_PIX,Pag_Entrega_Vale_Refeicao,Pag_Entrega_Dinheiro,Data_Scraping
https://...,McDonald's,15.0,"Av Rondon Pacheco, 1311",Tabajaras,Uberlandia,MG,38400-242,True,True,True,True,True,True,False,False,True,2025-06-15 19:07:25
```

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### PersonalizaÃ§Ã£o do Scraper

```python
from src.ifood_scraper import IFoodScraper

# Criar scraper personalizado
scraper = IFoodScraper(
    n_scrolls=15,           # NÃºmero de cliques em "Ver mais"
    timeout=20,             # Timeout em segundos
    output_path="dados.csv" # Caminho personalizado
)

# Executar scraping
success = scraper.scrape()
```

### ConfiguraÃ§Ã£o de LocalizaÃ§Ã£o

O scraper detecta automaticamente sua localizaÃ§Ã£o atravÃ©s do iFood, mas vocÃª pode modificar as coordenadas padrÃ£o no cÃ³digo:

```python
# Em ifood_scraper.py, mÃ©todo _get_user_location()
return {
    'general_lat': -18.9187,    # Latitude padrÃ£o (UberlÃ¢ndia)
    'general_lng': -48.2772,    # Longitude padrÃ£o
    'delivery_lat': -18.9187,
    'delivery_lng': -48.2772,
    'geohash': None
}
```

## ğŸ”§ Principais Classes

### `IFoodScraper`
Classe principal para scraping de dados bÃ¡sicos dos restaurantes.

**MÃ©todos principais:**
- `scrape()` - Executa o processo completo de scraping
- `_load_restaurants()` - Navega e carrega mais restaurantes
- `_extract_all_data()` - Extrai todos os dados usando Beautiful Soup

### `RestaurantDetailsScraper`
Classe para extraÃ§Ã£o de detalhes completos (endereÃ§os + pagamentos).

**MÃ©todos principais:**
- `scrape_details()` - Extrai detalhes de todos os restaurantes
- `_extract_details_with_retry()` - Extrai dados com retry automÃ¡tico
- `_extract_payment_methods()` - Extrai mÃ©todos de pagamento

## ğŸ“ˆ Exemplos de Uso

### AnÃ¡lise BÃ¡sica dos Dados

```python
import pandas as pd

# Carregar dados
df = pd.read_csv('reports/bd_scrap_ifood_10_20250615_125239.csv')

# EstatÃ­sticas bÃ¡sicas
print(f"Total de restaurantes: {len(df)}")
print(f"Nota mÃ©dia: {df['Nota'].mean():.2f}")
print(f"Tipos de culinÃ¡ria: {df['Tipo de comida'].nunique()}")

# Top 10 tipos de culinÃ¡ria
print(df['Tipo de comida'].value_counts().head(10))
```

### AnÃ¡lise de MÃ©todos de Pagamento

```python
import pandas as pd

# Carregar dados detalhados
df_details = pd.read_csv('reports/details_bd_scrap_ifood_20250615_192715.csv')

# AnÃ¡lise de pagamentos
pix_aceito = df_details['Pag_Site_PIX'].sum()
print(f"Restaurantes que aceitam PIX: {pix_aceito}")

# Pedido mÃ­nimo mÃ©dio
print(f"Pedido mÃ­nimo mÃ©dio: R$ {df_details['Pedido_Minimo'].mean():.2f}")
```

## âš ï¸ ConsideraÃ§Ãµes Importantes

### Rate Limiting
- O scraper inclui delays entre requisiÃ§Ãµes para evitar sobrecarga
- Tempos de espera configurÃ¡veis para diferentes cenÃ¡rios

### Tratamento de Erros
- Retry automÃ¡tico em caso de falhas
- Logs detalhados de sucessos e erros
- Continuidade do processo mesmo com falhas individuais

### Responsabilidade
- **Use com responsabilidade** e respeite os termos de uso do iFood
- **NÃ£o sobrecarregue** os servidores com muitas requisiÃ§Ãµes simultÃ¢neas
- **Considere** usar apenas para fins educacionais ou de pesquisa

## ğŸ¤ ContribuiÃ§Ã£o

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ™‹â€â™‚ï¸ Suporte

Se vocÃª encontrar problemas ou tiver dÃºvidas:

1. Verifique os [Issues existentes](https://github.com/seu-usuario/ifood-scraper/issues)
2. Crie um novo Issue descrevendo o problema
3. Inclua logs de erro e detalhes do ambiente

---

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio!**